---
title: "Cogcom exam"
author: "Sigrid"
date: "12/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages, echo = FALSE}
pacman::p_load(tidyverse, MuMIn, pastecs, WRS2, data.table, magrittr, dplyr, ggplot2, lme4, boot, lmerTest, caret, e1071, car, multcomp, reshape2)

```


```{r JULIE START HER}

new_df <- read_csv("data_done.csv")

```


```{r counting conditions and estimate }

# Counting the participant in condition and estimate
table(new_df$condition)
table(new_df$estimate)

# separating into older than and younger than 20 years

a1_old <- table(new_df$condition == "A" & new_df$estimate == 1 & new_df$alder >= 20)
a2_old <- table(new_df$condition == "A" & new_df$estimate == 2 & new_df$alder >= 20)
b1_old <- table(new_df$condition == "B" & new_df$estimate == 1 & new_df$alder >= 20)
b2_old <- table(new_df$condition == "B" & new_df$estimate == 2 & new_df$alder >= 20)

a1_ung <- table(new_df$condition == "A" & new_df$estimate == 1 & new_df$alder < 20)
a2_ung <- table(new_df$condition == "A" & new_df$estimate == 2 & new_df$alder < 20)
b1_ung <- table(new_df$condition == "B" & new_df$estimate == 1 & new_df$alder < 20)
b2_ung <- table(new_df$condition == "B" & new_df$estimate == 2 & new_df$alder < 20)


a1_old
a2_old
b1_old
b2_old
a1_ung
a2_ung
b1_ung
b2_ung

# for reporting numbers in the text
new_df$alder <- as.numeric(new_df$alder)
mean(new_df$alder)
sd(new_df$alder)
summary(new_df$kÃ¸n == "Kvinde")

```

```{r Hyp 1a mean speed estimate according to condition}

#changing class to be able to use group_by
new_df$condition <- as.factor(new_df$condition)
class(new_df$condition)

#making a new dataframe grouped by condition
by_cond <- group_by(new_df, condition)

#calculating mean estimate of speed according to condition
by_cond %>% summarise(mean(hastighed1))

```

```{r visualizing the data in general - make better, not usefull right now}

ggplot(new_df, aes(hastighed1, ID)) + geom_point() + geom_smooth(method = lm)

ggplot(new_df, aes(condition, hastighed1)) + geom_point() + geom_smooth(method = lm)


```

### Hypothesis 1a
In order to conduct a t-test the assumption of normally distributed data must be checked (parametric t-test).

```{r Hyp 1a - t-test assumptions hastighed/condition}

#from class 6 notes filled

#first, remove outliers from the whole data (everything 3 sd away from the mean)
#calculate z score
new_df$rt_z = (new_df$hastighed1 -mean(new_df$hastighed1))/sd(new_df$hastighed1)

#filter data 
no_outliers = new_df %>% filter(rt_z > -3 & rt_z < 3) 

#subsetting data
condA <- no_outliers %>% filter(condition == "A")
condB <- no_outliers %>% filter(condition == "B")

############ Checking Assumptions for Condition A
#histogram
ggplot(condA, aes(x = condA$hastighed1)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.4) +
  ggtitle("Distribution of speed estimate1 in condition A") +
  stat_function(fun = dnorm, args = list(mean = mean(condA$hastighed1, na.rm = TRUE), sd = sd(condA$hastighed1, na.rm = TRUE)), colour = "red", size = 1) +
  theme_minimal()

#qqplot
ggplot(condA, aes(sample = hastighed1)) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for speed estimate 1 data in Condition A") +
  theme_minimal()


############ Checking Assumptions for Condition B
#histogram
ggplot(condB, aes(x = condB$hastighed1)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.4) +
  ggtitle("Distribution of speed estimate1 in condition B") +
  stat_function(fun = dnorm, args = list(mean = mean(condB$hastighed1, na.rm = TRUE), sd = sd(condB$hastighed1, na.rm = TRUE)), colour = "blue", size = 1) +
  theme_minimal()

#qqplot
ggplot(condB, aes(sample = hastighed1)) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for speed estimate 1 data in Condition A") +
  theme_minimal()


#stat.desc
round(pastecs::stat.desc(cbind(condA$hastighed1, condB$hastighed1), basic = FALSE, norm = TRUE), digits = 2)


```

Conclusion about the data being normally distributed or not:
Visually the data do not look normally distributed in any way, however it looks a bit better numerically (despite Shapiro Willks test being significant = not normally distributed data). I will try to transform the data. 

```{r Hyp 1a - transforming the data}

#logging the data for both conditions
condA <- condA %>% mutate(rt_log = log(condA$hastighed1), 
                                    rt_sqrt = sqrt(condA$hastighed1),
                                    rt_inv = 1/condA$hastighed1)

condB <- condB %>% mutate(rt_log = log(condB$hastighed1), 
                                    rt_sqrt = sqrt(condB$hastighed1),
                                    rt_inv = 1/condB$hastighed1)

#checking numeric values for both conditions with the logged data
round(pastecs::stat.desc(cbind(condA$rt_log, condA$rt_sqrt, condA$rt_inv, condB$rt_log, condB$rt_sqrt, condB$rt_inv), basic = F, norm = TRUE), digits = 2)

# It seems that the log and the squareroot transformations fit the data better than the reciprocal transformation.


```

Visualizing the transformed data, but only the log and squareroot transformed data because it seemed to fit the data better than the reciprocal transformation. 

```{r Hyp 1a visual inspection of the transformed data}

#Check assumptions again
############ Checking Assumptions for Condition A (best candidates: log and sqrt)
#histogram
ggplot(condA, aes(x = rt_log)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.25) +
  ggtitle("Distribution of speed estimate 1 data (log transformed) in Condition A") +
  stat_function(fun = dnorm, args = list(mean = mean(condA$rt_log, na.rm = TRUE), sd = sd(condA$rt_log, na.rm = TRUE)), colour = "darkgreen", size = 1) +
  theme_minimal()

#qqplot
ggplot(condA, aes(sample = rt_log )) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for speed estimate 1 data (log transformed) in Condition 1") +
  theme_minimal()

#histogram
ggplot(condA, aes(x = rt_sqrt)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.25) +
  ggtitle("Distribution of speed estimate 1 data (squareroot transformed) in Condition A") +
  stat_function(fun = dnorm, args = list(mean = mean(condA$rt_sqrt, na.rm = TRUE), sd = sd(condA$rt_sqrt, na.rm = TRUE)), colour = "darkgreen", size = 1) +
  theme_minimal()

#qqplot
ggplot(condA, aes(sample = rt_sqrt)) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for speed estimate 1 data (squareroot transformed) in Condition A") +
  theme_minimal()


############ Checking Assumptions for Condition B (best candidates: log and sqrt)
#histogram
ggplot(condB, aes(x = rt_log)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.25) +
  ggtitle("Distribution of speed estimate 1 data (log transformed) in Condition B") +
  stat_function(fun = dnorm, args = list(mean = mean(condB$rt_log, na.rm = TRUE), sd = sd(condB$rt_log, na.rm = TRUE)), colour = "darkgreen", size = 1) +
  theme_minimal()

#qqplot
ggplot(condB, aes(sample = rt_log )) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for speed estimate 1 data (log transformed) in Condition B") +
  theme_minimal()


#histogram
ggplot(condB, aes(x = rt_sqrt)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.25) +
  ggtitle("Distribution of speed estimate 1 data (squareroot transformed) in Condition B") +
  stat_function(fun = dnorm, args = list(mean = mean(condB$rt_sqrt, na.rm = TRUE), sd = sd(condB$rt_sqrt, na.rm = TRUE)), colour = "darkgreen", size = 1) +
  theme_minimal()

#qqplot
ggplot(condB, aes(sample = rt_sqrt )) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for speed estimate 1 data (reciprocal transformed) in Condition B") +
  theme_minimal()


##### I'll continue with squareroot transformation. 
## bind cond1 and cond2 together and keep only the needed transformation #doesn't matter
#transformed_data <- bind_rows(condA, condB) %>%
  select(-c(rt_z, rt_log, rt_inv))

```

The data are still not normally distributed. I will therefore try different things:
- a parametric t-test on the transformed data
- a non-parametric independent t-test on the non-transformed data (between subject design)

```{r Hyp 1a - t-test on hastighed1 and condition}

#### parametric tests on the transformed data
t.test(transformed_data$rt_sqrt ~ transformed_data_sqrt$condition)

# we need the mean and the SD of the data when reporting the results
# calculating the SD of the mean of estimating spee 1 data according to condition on the transformed data
condA %>% summarise(sd(rt_sqrt))
condB %>% summarise(sd(rt_sqrt))

#### non-parametric test on non-transformed data
WRS2::yuen(hastighed1 ~ condition, new_df)

# need the mean and SD when reporting the results of the t-test
# calculating the mean of estimating speed1 according to condition on the non-transformed data
#changing class to be able to use group_by
new_df$condition <- as.factor(new_df$condition)
class(new_df$condition)

#making a new dataframe grouped by condition
by_cond <- group_by(new_df, condition)

#calculating mean estimate of speed according to condition
by_cond %>% summarise(mean(hastighed1))

#calculating the SD of estimate of speed according to condition
by_cond %>% summarise(sd(hastighed1))


```
Not significant results....

From the parametric t-test on the sqrt transformed data: do not use!
Using an independent t-test, we found that condition B ("smadrede") did not significantly increase the average speed estimate of the car, t(x) = x, p x , (M condA = x, M condB = x, SD condA = x, SD condB = x)

From the non-parametric t-test on the non-transformed data:
*Using a robust independent t-test, we found that condition B ("smadrede") did not significantly increase the average speed estimate of the car, t(79.13) = 0.7293, p >.05 (p = .47), (M condA = 84.31, M condB = 90.77, SD condA = 22.68, SD condB = 29.71)*

```{r Hyp 1a - visualizing the t-tests}

transformed_data$condition <- as.factor(transformed_data$condition)

# the transformed data - do not use this graph because we do not use this test
ggplot(transformed_data, aes(x = condition, y = rt_sqrt, colour = condition)) +
  theme_minimal() +
  labs(x = "Condition", y = "Speed estimate 1 (squareroot transformation)") +
  geom_boxplot(width = 0.5) +
  ggtitle("Box Plot: Squareroot transformed speed estimate 1 data depending on condition") +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1)


# trying the non-transformed data THIS ONE IS USED IN THE REPORT
new_df$condition <- as.factor(new_df$condition)
ggplot(new_df, aes(x = condition, y = hastighed1, colour = condition)) +
  theme_minimal() +
  labs(x = "Condition (A = 'hit', B = 'smashed')", y = "Speed estimate in km/h") +
  geom_boxplot(width = 0.5) +
  ggtitle("Speed estimate according to condition") +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1) + theme(legend.position = 'none')
  

#trying something - not used
rplot <- ggplot(transformed_data_sqrt, aes(x = condition, y = rt_sqrt, colour = condition)) +
  theme_minimal() +
    labs(x = "Condition", y = "Squareroot transformed speed estimate 1 data") 

#Box plot - looks weird - not used
rplot +
  geom_boxplot(width = 0.5) +
  ggtitle("Box Plot with mean") +
  stat_summary(fun.y = mean, geom = "point", shape = 23, colour = "Black") + geom_bar(aes(fill = condition), stat='summary', fun.y = mean, width = 0.5) +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1) +
  ggtitle("Using Standard Error of the Mean") 


#Violin plot - not used
rplot +
  geom_violin() +
  ggtitle("Violin Plot") +
  stat_summary(fun.y = mean, geom = "point", shape = 23, colour = "Black") +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1)

```

### LOGISIC REGRESSION - Glas spÃ¸rgsmÃ¥l assumptions checking
(see class 10 notes filled)

*not required*
 - logistic regression does not require a linear relationship between the dependent and independent variables.  
      - the error terms (residuals) do not need to be normally distributed.
      - homoscedasticity is not required
      
*required*
  - binary logistic regression requires the dependent variable to be binary, i.e. a factor with two levels: 
  Sigrid: Yes, glasskÃ¥r har to mulige svar, ja eller nej. 

  - logistic regression requires the observations to be independent of each other.  In other words, the observations should not come from repeated measurements or matched data - USE glmer() TO BUILD MIXED EFFECT MODELS THAT DEAL WITH VIOLATION OF THIS ASSUMPTION:
  Sigrid: Yes, independent-measures design
      
  - logistic regression requires there to be little or no multicollinearity among the independent variables.  This means that the independent variables should not be too highly correlated with each other:
  Sigrid: They are not (condition and glasskÃ¥r question are not highly correlated)
      
  - logistic regression assumes linearity of independent variables and log odds.
  *Sigrid: I guess? using plot() I get two plots with a linear line but I'm not sure what it means*
  
  - logistic regression typically requires a large sample size.  A general guideline is that you need at minimum of 10 cases with the least frequent outcome for each independent variable in your model. For example, if you have 5 independent variables and the expected probability of your least frequent outcome is .10, then you would need a minimum sample size of 500 (10*5 / .10).
  Sigrid: I have 1 independent variable and the least frequent outcome of this is 
  70/142 =  0.4929577
  i.e. 49 * 1 / 0.49 = 100
  We have more than 100 observations in our data set, so this assumption is met as well.

```{r Hyp 1b - glas spÃ¸rgsmÃ¥l - logistic regression} 

# see class 10 notes filled
new_df$glasskÃ¥r <- as.factor(new_df$glasskÃ¥r)

#change levels
new_df$glasskÃ¥r <- relevel(new_df$glasskÃ¥r, "n")
#check levels (n og condA skal vÃ¦re baseline)
levels(new_df$glasskÃ¥r)
levels(new_df$condition)
new_df$condition <- relevel(new_df$condition, "A")

#GLM model
m <- glm(glasskÃ¥r ~ condition, new_df, family = binomial)
plot(m)
summary(m)

# the probability of answering yes in condition a
round(boot::inv.logit(-0.58779), digits = 4)
# = 35.71% 

# the probability of answering yes in condition b
round(boot::inv.logit(-0.58779 - 0.02532), digits = 4)
# = 35.14%

#which means that the probability of answering no in condA is 
1-0.3571
# = 64.29%

#which means that the probability of answering no in condB is 
1-0.3514
# = 64.86%


#MuMIn::r.squaredGLM(m) - doesn't work, not used

# trying to make an interesing plot, not really working out, Julie do what you wanna do :-)
ggplot(new_df, aes(x = glasskÃ¥r, fill = condition)) +
  theme_minimal() + geom_bar(width = 0.5) #+ stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1) + labs(x = "Condition", y = "", title = "") + theme(legend.position = 'none')

```

### Reporting the results APA-style - not sure this is how to do it

Results of the binary logistic regression indicated that there was no significant association between answering the glass question positively given a specific condition, beta-estimate = -0.58, SE = 0.25, p<.05, while changing the condition from A to B, beta-estimate = -0.03, SE = 0.35, p>.05 (p = 0.94). I.e. the answer of the glas question is not significantly modulated by a given condition. 

Also comment on the null deviance versus the residual deviance (does not look like the model is a good fit to the data, maybe the assumptions are violated??) and the deviance residuals (min, 1Q, median, 3q, max) are not specifically symmetrical.. 


```{r participants - kÃ¸retimer vs computertimer + kÃ¸rekort}

#making new data frames separating age above and younger than 20 years 
df_old <- new_df %>% subset(new_df$alder >= 20) 
df_ung <- new_df %>%  subset(new_df$alder < 20)

# getting the gender distribution of each of these groups
summary(df_old$kÃ¸n == "Kvinde")
summary(df_ung$kÃ¸n == "Kvinde")

#changing classes
df_old$computertimer <- as.numeric(df_old$computertimer)
df_old$kÃ¸retimer <- as.numeric(df_old$kÃ¸retimer)
class(df_old$computertimer)
class(df_old$kÃ¸retimer)

# calculating the means for the old age group
m_old_com <- round(mean(df_old$computertimer), digits = 2)
m_old_kÃ¸r <- round(mean(df_old$kÃ¸retimer), digits = 2)

#changing classes
df_ung$computertimer <- as.numeric(df_ung$computertimer)
df_ung$kÃ¸retimer <- as.numeric(df_ung$kÃ¸retimer)
class(df_ung$computertimer)
class(df_ung$kÃ¸retimer)

#calculating the means for the young age group
m_ung_com <- round(mean(df_ung$computertimer), digits = 2)
m_ung_kÃ¸r <- round(mean(df_ung$kÃ¸retimer), digits = 2)

sd(df_ung$computertimer)

###### kÃ¸rekort eller ej
# calculating the number of people have kÃ¸rekort both in general and according to the different age groups 
class(new_df$kÃ¸rekort)
new_df$kÃ¸rekort <- as.factor(new_df$kÃ¸rekort)
class(new_df$kÃ¸rekort)

drivers_lice <- data.frame(ID = sample(letters, 144, rep = TRUE))
drivers_lice %>% 
  group_by(new_df$kÃ¸rekort) %>% 
  summarise(no_rows = length(ID))

round(74/144, digits = 4)
# = 51.39% har kÃ¸rekort generelt

drivers_lice_old <- data.frame(ID = sample(letters, 63, rep = TRUE))
drivers_lice_old %>% 
  group_by(df_old$kÃ¸rekort) %>% 
  summarise(no_rows = length(ID))

round(59/63, digits = 4)
# = 93.65% af dem over 20 Ã¥r har kÃ¸rekort

drivers_lice_ung <- data.frame(ID = sample(letters, 81, rep = TRUE))
drivers_lice_ung %>% 
  group_by(df_ung$kÃ¸rekort) %>% 
  summarise(no_rows = length(ID))

round(15/81, digits = 4)
# = 18.52% af dem under 20 Ã¥r har kÃ¸rekort

summary(df_ung$kÃ¸n == "Kvinde")
summary(df_old$kÃ¸n == "Kvinde")
```


```{r Hyp 2a Ã¦ndre svar percentage}

# calculating the number of people who changed their answers in general
class(new_df$Ã¦ndre_svar)
new_df$Ã¦ndre_svar <- as.factor(new_df$Ã¦ndre_svar)

nyt_svar <- data.frame(ID = sample(letters, 144, rep = TRUE))
nyt_svar %>% 
  group_by(new_df$Ã¦ndre_svar) %>% 
  summarise(no_rows = length(ID))

round(21/144, digits = 4)
# = 14.58% changed their answer, rated a second time

# calculating the number of YOUNG people who changed their answers
class(df_ung$Ã¦ndre_svar)

nyt_svar_ung <- data.frame(ID = sample(letters, 81, rep = TRUE))
nyt_svar_ung %>% 
  group_by(df_ung$Ã¦ndre_svar) %>% 
  summarise(no_rows = length(ID))

round(16/81, digits = 4)
# = 19.75% 

# calculating the number of OLD people who changed their answers
class(df_old$Ã¦ndre_svar)

nyt_svar_old <- data.frame(ID = sample(letters, 63, rep = TRUE))
nyt_svar_old %>% 
  group_by(df_old$Ã¦ndre_svar) %>% 
  summarise(no_rows = length(ID))

round(5/63, digits = 4)
# = 7.94%

# the number of people in each age group and their gender who changed their answer
summary(df_svar$kÃ¸n == "Kvinde" & df_svar$under_20 == TRUE)
summary(df_svar$kÃ¸n == "Mand" & df_svar$under_20 == TRUE)

summary(df_svar$kÃ¸n == "Kvinde" & df_svar$under_20 == FALSE)
summary(df_svar$kÃ¸n == "Mand" & df_svar$under_20 == FALSE)



```
Now testing if age significantly predicts if people will change their answer.. 

remember assumptions!! (have not been checked yet)

```{r Hyp 2a Ã¦ndre svar - simple logistic regression}

new_df$Ã¦ndre_svar <- as.factor(new_df$Ã¦ndre_svar)
levels(new_df$Ã¦ndre_svar)
new_df$Ã¦ndre_svar <- relevel(new_df$Ã¦ndre_svar, "n")

new_df$under_20 <- new_df$alder < 20
class(new_df$under_20)

new_df$under_20 <- as.factor(new_df$under_20)
class(new_df$under_20)

levels(new_df$under_20)
new_df$under_20 <- relevel(new_df$under_20, "TRUE")
levels(new_df$under_20)


m_svar <- glm(Ã¦ndre_svar ~ under_20, family = binomial, data = new_df)
#m_svar <- glm(Ã¦ndre_svar ~ under_20, family = binomial, data = no_outliers)

plot(m_svar)
summary(m_svar) 

boot::inv.logit(-1.4018)
# = 19.75% significant chance of changing one's answer if one is below 20 y p<.001 (p=6.13e-07)


boot::inv.logit(-1.4018 - 1.0492)
# = 7.94%, p>.05 

```
A significant effect of the younger group was found, beta = -1.4018, SE = 0.28, z-value = -5.02, p<.001 (p=5.09e-07), while the other age group only came very close to being significant, beta = -1.0492, SE = 0.54, z-value = -1.93, p>.05 (p = 0.0534).
I.e. choosing to change one's answer can not be concluded to significantly be modulted by age (below or above 20 years). men det er lige pÃ¥ vippen!


```{r Hyp 2b det nye svar - forskel i procent}

#changing classes
new_df$alder <- as.numeric(new_df$alder)
new_df$kÃ¸n <- as.factor(new_df$kÃ¸n)
new_df$estimate <- as.factor(new_df$estimate)

#calculating change in percentage
new_df$speed_change <- ((new_df$hastighed1-new_df$hastighed2)/new_df$hastighed1)*100

# how many observations do we have with a changed answer
summary(new_df$Ã¦ndre_svar == "j")
# 21 observations

#making a new dataframe with only these observations
df_svar <- subset(new_df, new_df$Ã¦ndre_svar == "j")

#making a new column where everything is in positive numbers
df_svar$speed_change_plus <- sqrt((df_svar$speed_change)^2)

#calculating the mean change no matter which direction they were pushed in
round(mean(df_svar$speed_change_plus), digits = 2)
#29.16 km/h
round(sd(df_svar$speed_change_plus), digits = 2)

# group the data frame into estimate 1 (hurtigere) and estimate 2 (langsommere)
df_svar_group <- group_by(df_svar, estimate)
df_svar_group_ung <- subset(df_svar_group, df_svar_gender$under_20 == "TRUE")

# calculate the means once again for the two estimates
df_svar_group %>% summarise(round(mean(speed_change_plus), digits = 2))
# calculating the standard deviation for the two estimates
df_svar_group %>% summarise(round(sd(speed_change_plus), digits = 2))

# calculating if there was a significant difference between men and women
df_svar_gender <- df_svar %>% group_by(df_svar$kÃ¸n)
df_svar_gender %>% summarise(round(mean(speed_change_plus), digits = 2))
df_svar_gender %>% summarise(round(sd(speed_change_plus), digits = 2))

WRS2::yuen(speed_change_plus ~ kÃ¸n, data = df_svar_gender)

# trying the same with the young age group 
df_svar_gender_ung <- subset(df_svar_gender, df_svar_gender$under_20 == "TRUE")

df_svar_gender_ung %>% summarise(round(mean(speed_change_plus), digits = 2))
df_svar_gender_ung %>% summarise(round(sd(speed_change_plus), digits = 2))

WRS2::yuen(speed_change_plus ~ kÃ¸n, data = df_svar_gender_ung)

# trying the same with the old age group 
df_svar_gender_old <- subset(df_svar_gender, df_svar_gender$under_20 == "FALSE")

df_svar_gender_old %>% summarise(round(mean(speed_change_plus), digits = 2))
df_svar_gender_old %>% summarise(round(sd(speed_change_plus), digits = 2))

WRS2::yuen(speed_change_plus ~ kÃ¸n, data = df_svar_gender_old)

# visualizing the data - this is the used graph, do not change!
ggplot(df_svar_gender_ung, aes(x = kÃ¸n, y = speed_change_plus, fill = kÃ¸n)) +
  theme_minimal() + geom_boxplot(width = 0.5) + stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1) + coord_cartesian(ylim = c(0,50)) + labs(x = "Gender", y = "Percentage change from first to second estimate of speed", title = "Percentage change in speed estimae according to gender (younger than 20 y)") + scale_fill_discrete(name = "Gender", labels = c("Women", "Men"))


# trying to make a better graph by using Kenneth's code
df_svar_gender_ung$mean_hastighed1 <- mean(df_svar_gender_ung$hastighed1)
df_svar_gender_ung$mean_hastighed2 <- mean(df_svar_gender_ung$hastighed2)

# plot hvor det gÃ¥r fra estimate 1 til estimate 2 i gennemsnit ift kÃ¸n og kun den unge gruppe
ggplot(df_svar_gender_ung, aes(x = c(mean_hastighed1, mean_hastighed2), speed_change_plus, fill = kÃ¸n)) + geom_point(stat = 'summary', fun.y = mean) +
  stat_summary(fun.y = mean, geom = "line", aes(group = c(mean_hastighed1, mean_hastighed2))) +
  geom_errorbar(stat = 'summary',
                fun.data = mean_se,
                width = 0.1) +
  labs(x = "Paper", y = "Mean Sentiment Score", color = "Party") +
  scale_y_continuous(breaks = seq(-0.005, 0.025, 0.005))


#+ theme(legend.position = 'none')
 #geom_pointrange() + stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1)

```
The women who chose to change their answer changed it on average by 18.61 percent, where as the men changed it by 38.75%. Testing if this is signifcant by making a robust t-test.

There was found no significant difference between the mean change of speed estimate for men and women in general, t(10.11) = 1.41, p>.05 (p = .19), (M women = 18.61, SD women = 10.75 , M men = 38.75, SD = 34.63)

*There was found a significant difference between the mean change of speed estimate for men and women in the age group below 20 years of age, t(10) = 2.25, p<.05 (p = 0.04824) (M women = 14.87, M men = 31.23, SD women = 10.53, SD men = 17.41)* (assumptions for a possible parametric t-test have not been checked yet!)

There was found no significant difference between the mean change of speed estimate for men in women in the older age group (equals to or above 20 years of age), t(1) = 0.78, p>.05 (p = .58) (M women = 27.35, M men = 72.57, SD women = 4.97, SD men = 82.28)

```{r parti - t-test between computer hours and driving hours + assumptions}

### checking assumptions
new_df$computertimer <- as.numeric(new_df$computertimer)
new_df$kÃ¸retimer <- as.numeric(new_df$kÃ¸retimer)

# removing outliers 
new_df$ct_z = (new_df$computertimer - mean(new_df$computertimer))/sd(new_df$computertimer) 
new_df$kt_z = (new_df$kÃ¸retimer - mean(new_df$kÃ¸retimer))/sd(new_df$kÃ¸retimer)
 
#filter data 
no_outliers_ct = new_df %>% filter(ct_z > -3 & ct_z < 3) 
no_outliers_kt = new_df %>% filter(kt_z > -3 & kt_z < 3) 

#subsetting data
df_ung_no_ct <- no_outliers_ct %>% filter(under_20 == "TRUE")
df_ung_no_kt <- no_outliers_kt %>% filter(under_20 == "TRUE")

df_old_no_ct <- no_outliers_ct %>% filter(under_20 == "FALSE")
df_old_no_kt <- no_outliers_ct %>% filter(under_20 == "FALSE")

############ Checking Assumptions for df_ung_no_ct (young group computertimer)
#histogram
ggplot(df_ung_no_ct, aes(x = df_ung_no_ct$computertimer)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.4) +
  ggtitle("Distribution of computer hours in young group") +
  stat_function(fun = dnorm, args = list(mean = mean(df_ung_no_ct$computertimer, na.rm = TRUE), sd = sd(df_ung_no_ct$computertimer, na.rm = TRUE)), colour = "red", size = 1) +
  theme_minimal()

#qqplot
ggplot(df_ung_no_ct, aes(sample = df_ung_no_ct$computertimer)) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for computer hours in young group") +
  theme_minimal()


############ Checking Assumptions for df_ung_no_kt (young group kÃ¸retimer)
#histogram
ggplot(df_ung_no_kt, aes(x = df_ung_no_kt$kÃ¸retimer)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.4) +
  ggtitle("Distribution of driving hours young group") +
  stat_function(fun = dnorm, args = list(mean = mean(df_ung_no_kt$kÃ¸retimer, na.rm = TRUE), sd = sd(df_ung_no_kt$kÃ¸retimer, na.rm = TRUE)), colour = "blue", size = 1) +
  theme_minimal()

#qqplot
ggplot( df_ung_no_kt, aes(sample = kÃ¸retimer)) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for driving hours in young group") +
  theme_minimal()


############ Checking Assumptions for df_old_no_ct (old group computertimer)
#histogram
ggplot(df_old_no_ct, aes(x = df_old_no_ct$computertimer)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.4) +
  ggtitle("Distribution of computer hours old group") +
  stat_function(fun = dnorm, args = list(mean = mean(df_old_no_ct$computertimer, na.rm = TRUE), sd = sd(df_old_no_ct$computertimer, na.rm = TRUE)), colour = "blue", size = 1) +
  theme_minimal()

#qqplot
ggplot(df_old_no_ct, aes(sample = computertimer)) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for computer hours old group") +
  theme_minimal()


############ Checking Assumptions for df_old_no_kt (old group kÃ¸retimer)
#histogram
ggplot(df_old_no_kt, aes(x = df_old_no_kt$kÃ¸retimer)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.4) +
  ggtitle("Distribution of driving hours old group") +
  stat_function(fun = dnorm, args = list(mean = mean(df_old_no_kt$kÃ¸retimer, na.rm = TRUE), sd = sd(df_old_no_kt$kÃ¸retimer, na.rm = TRUE)), colour = "blue", size = 1) +
  theme_minimal()

#qqplot
ggplot( df_old_no_kt, aes(sample = kÃ¸retimer)) +
  stat_qq() +
  stat_qq_line(colour = 'red') +
  ggtitle("Qqplot for driving hours in old group") +
  theme_minimal()

#stat.desc
round(pastecs::stat.desc(cbind(df_ung_no_ct$computertimer, df_old_no_ct$computertimer, df_ung_no_kt$kÃ¸retimer, df_old_no_kt$kÃ¸retimer), basic = FALSE, norm = TRUE), digits = 2)

###### transforming the data


#logging the data for both conditions
df_ung_no_ct <- df_ung_no_ct %>% mutate(ung_ct_log = log(df_ung_no_ct$computertimer), 
                                    ung_ct_sqrt = sqrt(df_ung_no_ct$computertimer),
                                    ung_ct_inv = 1/df_ung_no_ct$computertimer)

df_ung_no_kt <- df_ung_no_kt %>% mutate(ung_kt_log = log(df_ung_no_kt$kÃ¸retimer), 
                                    ung_kt_sqrt = sqrt(df_ung_no_kt$kÃ¸retimer),
                                    ung_kt_inv = 1/df_ung_no_kt$kÃ¸retimer)

df_old_no_ct <- df_old_no_ct %>% mutate(old_ct_log = log(df_old_no_ct$computertimer), 
                                    old_ct_sqrt = sqrt(df_old_no_ct$computertimer),
                                    old_ct_inv = 1/df_old_no_ct$computertimer)

df_old_no_kt <- df_old_no_kt %>% mutate(old_kt_log = log(df_old_no_kt$kÃ¸retimer), 
                                    old_kt_sqrt = sqrt(df_old_no_kt$kÃ¸retimer),
                                    old_kt_inv = 1/df_old_no_kt$kÃ¸retimer)

#checking numeric values for both conditions with the logged data
round(pastecs::stat.desc(cbind(df_ung_no_ct$ung_ct_log, df_ung_no_ct$ung_ct_sqrt, df_ung_no_ct$ung_ct_inv, df_ung_no_kt$ung_kt_log, df_ung_no_kt$ung_kt_sqrt, df_ung_no_kt$ung_kt_inv, df_old_no_ct$old_ct_log, df_old_no_ct$old_ct_sqrt, df_old_no_ct$old_ct_inv, df_old_no_kt$old_kt_log, df_old_no_kt$old_kt_sqrt, df_old_no_kt$old_kt_inv), basic = F, norm = TRUE), digits = 2)

# looks terrible continuing with the non-transformed data and a robust t-test

#non-parametric t-test (robust t-test)
WRS2::yuen(computertimer ~ under_20, data = new_df)
sd(df_ung$computertimer)
sd(df_old$computertimer)

#non-parametric t-test (robust t-test)
WRS2::yuen(kÃ¸retimer ~ under_20, data = new_df)
sd(df_ung$kÃ¸retimer)
sd(df_old$kÃ¸retimer)

```

The data did not meet the assumptions of a parametric t-test. therefore:
Performing a robust t-test it was found that there is a significant difference between the average hours spent playing computer or other gaming consoles weekly between people younger than 20 years of age and people equal to or older than 20 years of age, t(74.81) = 3.34, p<.01 (p=0.0013) (M_young = 4.2, SD = 7.45, M_old = 2.41, SD = 5.51). 

Likewise when performing a robust t-test on the difference between the agerage number of hours spent driving a vehicle weekly there was found to be a significant difference between the two age groups, t(43.13) = 4.43, p<.0001 (p=6e-05, 0.000005) (M_young = 0.9, SD = 2.19, M_old = 3.62, SD = 3.84)

```{r parti - kÃ¸retimer + computertimer visualization}

# visualizing the data without transforming it
ggplot(new_df, aes(under_20, computertimer, fill = under_20)) +
  theme_minimal() +
  labs(x = "Age below 20 (TRUE) and equals to or above 20 years (FALSE)", y = "Average amount of hours spent playing computer etc weekly") +
  geom_boxplot(width = 0.5) +
  ggtitle("Average amount of hours spent playing computer etc weekly depending on age group") +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1) + coord_cartesian(ylim = c(0,15)) + theme(legend.position = 'none')

ggplot(new_df, aes(under_20, kÃ¸retimer, fill = under_20)) +
  theme_minimal() +
  labs(x = "Age below 20 (TRUE) and equals to or above 20 years (FALSE)", y = "Average amount of hours spent driving weekly") +
  geom_boxplot(width = 0.5) +
  ggtitle("Average hours spent driving weekly depending on age group") +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = 'black', width = 0.1) + coord_cartesian(ylim = c(0,15)) + theme(legend.position = 'none')

```


```{r giving credits}

#giving credits to R
citation()

# finding citations for packages 
citation('WRS2') 

```


```{r cut outs}
#cond_a <- new_df$condition == "A"

#making a new dataframe grouped by estimate - to use later
class(new_df$estimate)
new_df$estimate <- as.factor(new_df$estimate) 
by_estimate <- group_by(new_df, estimate)
 

class(new_df$computertimer)
new_df$computertimer <- as.factor(new_df$computertimer)
class(new_df$computertimer)
levels(new_df$computertimer)

#df_age <- new_df %>% group_by(new_df$alder >=20 | new_df$alder < 20)

```



